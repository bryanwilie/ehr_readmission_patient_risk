{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d96543f-b935-4a42-9b63-d7e7f23dbc5a",
   "metadata": {},
   "source": [
    "## Reproducing LePendu et al steps\n",
    "\n",
    "Annotates clinical text from EHR systems -> extract disease and drug mentions from the EHR.<br>\n",
    "\n",
    "Reproduce steps:\n",
    "1. [DONE] Obtain lexicon from ontologies downloaded from [UMLS](https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html) (umls-2021AB-full.zip), using [Owlready2](https://pypi.org/project/Owlready2/)\n",
    "2. [TODO] Annotate by string matching the text to the lexicon downloaded\n",
    "3. [DONE] Apply negex trigger rules to separate negated terms (to incorporate negation detection—the ability to discern whether a term is negated within the context of the narrative.)\n",
    "4.1. [DONE] We compile terms (both positive and negative) into a temporally ordered series of sets for each patient and ..\n",
    "    2. [TODO] combine them with coded and structured data when possible\n",
    "5. [TODO] We reason over the structure of the ontologies to normalize and to aggregate terms for further analysis\n",
    "6. From each note, output: set of negated terms, set of non-negated terms\n",
    "\n",
    "__Additional:__\n",
    "1. __Ontology:__<br>\n",
    "    For this study, use a subset of those ontologies (Table 3) that are most relevant to clinical domains, including:\n",
    "    - Unified Medical Language System (UMLS) terminologies such as __SNOMED-CT__, \n",
    "    - the __National Drug File (NDFRT)__, and \n",
    "    - __RxNORM__\n",
    "    - as well as ontologies like the Human Disease Ontology. <br>\n",
    "    \n",
    "    The resulting lexicon contains __2.8 million unique terms.__\n",
    "2. The output of the annotation workflow is a set of __negated and non-negated terms__ from each note (Figure 1, step 3). <br>\n",
    "   As a result, for each patient we end up with a temporal series of terms mentioned in the notes (red denotes negated terms in Figure 1, step 4).<br>\n",
    "   We also include __manually encoded ICD9 terms__ for each patient encounter as additional terms.<br>\n",
    "   Because each encounter’s date is recorded, we can order each set of terms for a patient to create a timeline view of the patient’s record. <br>\n",
    "   Using the terms as features, we can define patterns of interest (such as patients with rheumatoid arthritis, who take rofecoxib, and then get myocardial infarctio), which we can use in data mining applications.\n",
    "3. __Normalizing and aggregating terms.__<br>\n",
    "We use the __RxNORM terminology__ to __normalize the drug having the trade name Vioxx into its primary active ingredient__, rofecoxib.<br>\n",
    "From the set of ontologies we use, the Annotator identifies all notes containing any string denoting this term as either its primary label or synonym.<br>\n",
    "We use __all other ontologies to normalize strings denoting rheumatoid arthritis or myocardial infarction__ and the Annotator identifies all notes containing them.<br>\n",
    "As an option, we can also enable reasoning to infer all subsumed terms, which increases the number of notes that we can identify beyond pure string matches.<br>\n",
    "For example, patients with Caplan’s or Felty’s syndrome may also fit the cohort of patients with rheumatoid arthritis.<br>\n",
    "Therefore, notes that mention these diseases can automatically be included as well even though their associated strings look nothing alike.<br>\n",
    "We did not use such reasoning for results reported in this specific study.\n",
    "4. Obtaining ICD9 discharge codes<br>\n",
    "Patient visits include in some cases the discharge diagnosis in the form of an ICD9 code. <br>\n",
    "The ICD9 codes for rheumatoid arthritis begin with 714 and the ICD9 code for myocardial infarction begins with 410. <br>\n",
    "We __include these manually encoded terms as part of the analysis__ as a __comparison against what we can find in the text itself__.\n",
    "5. We are also extending the system to discern additional contextual cues such as family history versus recent diagnosis.\n",
    "\n",
    "Timeline:\n",
    "1. day 1: Reproduce 1&2, and additional 1&2\n",
    "2. day 2: Reproduce 4.2. and additional 3&4\n",
    "3. day 3: Revise steps, read the paper again, Reproduce 5,6, and additional 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86901e4d-a098-4a73-954b-629f4787f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100) \n",
    "\n",
    "path = 'data_pool/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7797336f-3244-4e83-bdb3-0b2fd654c9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.iloc[0]['long_title'] Erythema nodosum with hypersensitivity reaction in tuberculosis, tubercle bacilli not found by bacteriological or histological examination, but tuberculosis confirmed by other methods [inoculation of animals]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>icd9_code</th>\n",
       "      <th>short_title</th>\n",
       "      <th>long_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01716</td>\n",
       "      <td>Erythem nod tb-oth test</td>\n",
       "      <td>Erythema nodosum with hypersensitivity reaction in tuberculosis, tubercle bacilli not found by b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01720</td>\n",
       "      <td>TB periph lymph-unspec</td>\n",
       "      <td>Tuberculosis of peripheral lymph nodes, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>01721</td>\n",
       "      <td>TB periph lymph-no exam</td>\n",
       "      <td>Tuberculosis of peripheral lymph nodes, bacteriological or histological examination not done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id icd9_code              short_title  \\\n",
       "0       1     01716  Erythem nod tb-oth test   \n",
       "1       2     01720   TB periph lymph-unspec   \n",
       "2       3     01721  TB periph lymph-no exam   \n",
       "\n",
       "                                                                                            long_title  \n",
       "0  Erythema nodosum with hypersensitivity reaction in tuberculosis, tubercle bacilli not found by b...  \n",
       "1                                                  Tuberculosis of peripheral lymph nodes, unspecified  \n",
       "2         Tuberculosis of peripheral lymph nodes, bacteriological or histological examination not done  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic_iii_demo = path + 'mimic-iii-clinical-database-demo-1.4/'\n",
    "df = pd.read_csv(mimic_iii_demo + 'D_ICD_DIAGNOSES.csv')\n",
    "print('df.iloc[0][\\'long_title\\']', df.iloc[0]['long_title'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b9861-0f21-4ce3-93de-d23f1f48b0ca",
   "metadata": {},
   "source": [
    "### Obtaining ontologies from UMLS\n",
    "\n",
    "Annotate by string matching the text to the lexicon downloaded\n",
    "\n",
    "More terminologies:\n",
    "- [UMLS Metathesaurus Vocabulary Documentation](nlm.nih.gov/research/umls/sourcereleasedocs/index.html)\n",
    "- [VSAC Downloadable Resources](https://vsac.nlm.nih.gov/download/ccda?rel=20210810)\n",
    "- [RxNorm](https://www.nlm.nih.gov/research/umls/rxnorm/index.html)\n",
    "- [CDE](https://cde.nlm.nih.gov/home)\n",
    "\n",
    "Some guide on querying:\n",
    "- [Documentation from source](https://bitbucket.org/jibalamy/owlready2/src/master/doc/)\n",
    "- [Owlready2](https://pypi.org/project/Owlready2/)\n",
    "- [How to extract/get all the terms(classes/properties) in an ontology](https://stackoverflow.com/questions/52655960/how-to-extract-get-all-the-termsclasses-properties-in-an-ontology)\n",
    "- [querying the owl ontology](https://stackoverflow.com/questions/22542348/querying-the-owl-ontology)\n",
    "- [SPARQL query](https://owlready2.readthedocs.io/en/v0.35/sparql.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e34bc3d-daf1-4653-ab62-173670817434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import get_ontology\n",
    "from owlready2.pymedtermino2.umls import import_umls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76d39dd-786a-4918-8c79-63397bb6201a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing UMLS from umls-2021AB-full.zip with Python version 3.8.8 and Owlready version 2-0.35...\n",
      "Full UMLS release - importing UMLS from inner Zip file 2021AB-full/2021ab-1-meta.nlm...\n",
      "  Parsing 2021AB/META/MRSTY.RRF.gz as MRSTY with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRRANK.RRF.gz as MRRANK with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRCONSO.RRF.aa.gz as MRCONSO with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRCONSO.RRF.ab.gz as MRCONSO with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRDEF.RRF.gz as MRDEF with encoding UTF-8\n",
      "Full UMLS release - importing UMLS from inner Zip file 2021AB-full/2021ab-2-meta.nlm...\n",
      "  Parsing 2021AB/META/MRREL.RRF.aa.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRREL.RRF.ab.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRREL.RRF.ac.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRREL.RRF.ad.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.aa.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ab.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ac.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ad.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ae.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.af.gz as MRSAT with encoding UTF-8\n",
      "Breaking ORIG cycles...\n",
      "    SNOMEDCT_US : 0 cycles found: \n",
      "    ICD10 : 0 cycles found: \n",
      "    SRC : 0 cycles found: \n",
      "Finalizing only properties and restrictions...\n",
      "Finalizing CUI - ORIG mapping...\n",
      "FTS Indexing...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'unique_terms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_terms' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# include more from: https://www.nlm.nih.gov/research/umls/sourcereleasedocs/index.html\n",
    "import_umls(\"umls-2021AB-full.zip\", terminologies = [\"ICD10\", \"SNOMEDCT_US\", \"CUI\"])\n",
    "\n",
    "PYM = get_ontology(\"http://PYM/\").load()\n",
    "PYM_classes_list = list(PYM.classes())\n",
    "\n",
    "terms = []\n",
    "for i in range(len(PYM_classes_list)):\n",
    "    str_class_selected = str(PYM_classes_list[i])\n",
    "    if '#' in str_class_selected:\n",
    "        strings_selected = str_class_selected[str_class_selected.index('#')+2:-1].replace(' ; ',';').split('; ')\n",
    "        terms.extend(strings_selected)\n",
    "\n",
    "unique_terms = list(set(terms))\n",
    "while '' in unique_terms:\n",
    "    unique_terms.pop(unique_terms.index(''))\n",
    "        \n",
    "print(len(unique_terms), 'unique terms obtained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2736a2b6-7ef2-47e7-a19b-8bd6952211f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUI[\"C0439111\"] # H\n",
      " ['H']\n",
      "SNOMEDCT_US[\"257967009\"] # H\n",
      " ['H']\n"
     ]
    }
   ],
   "source": [
    "terms = []\n",
    "for i in range(len(PYM_classes_list)):\n",
    "    str_class_selected = str(PYM_classes_list[i])\n",
    "    if '#' in str_class_selected:\n",
    "        strings_selected = str_class_selected[str_class_selected.index('#')+2:-1].replace(' ; ',';').split('; ')\n",
    "        if 'H' in strings_selected:\n",
    "            print(str_class_selected, strings_selected)\n",
    "        terms.extend(strings_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b958decf-470e-46f5-b536-f27ffe661892",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_clinical_text = \"This is a 31 year old male s/p seizure on ladder with resulting fall 15-20 feet on [**09-17**] \\\n",
    "                        now presenting to the T/SICU post surgical repair of multiple facial fractures, \\\n",
    "                        right mandibular fracture, and left distal radius fracture. \\\n",
    "                        He needs to remain intubated for 48 hours post-op. \\\n",
    "                        His past medical history is significant only for seizure disorder, \\\n",
    "                        and his only medication is depakote. He has no known allergies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98c98afa-4d62-4471-b3ed-422f5250167d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409 c\n",
      "18300 5\n",
      "19537 -2\n",
      "23501 z\n",
      "34599 a\n",
      "50498 S\n",
      "56555 m\n",
      "71021 48 hours\n",
      "79176 w\n",
      "88425 15\n",
      "103363 rem\n",
      "109455 cal\n",
      "125378 g\n",
      "127627 y\n",
      "134625 17\n",
      "158107 year\n",
      "169429 U\n",
      "176354 I\n",
      "176963 hour\n",
      "178763 s\n",
      "180525 t\n",
      "185016 k\n",
      "229427 rad\n",
      "236416 is\n",
      "236907 n\n",
      "241478 ft\n",
      "248897 2\n",
      "253897 20 feet\n",
      "263116 us\n",
      "275576 3\n",
      "282099 7\n",
      "285780 i\n",
      "307054 20\n",
      "329881 -1\n",
      "330978 r\n",
      "334461 d\n",
      "373637 31\n",
      "380794 u\n",
      "381711 0\n",
      "387280 8\n",
      "415304 4\n",
      "419479 ng\n",
      "419986 48\n",
      "420545 e\n",
      "434100 H\n",
      "440647 b\n",
      "451148 9\n",
      "463734 T\n",
      "472654 l\n",
      "486132 1\n",
      "486857 p\n",
      "486890 8 hours\n",
      "491100 f\n",
      "491383 o\n",
      "494675 C\n",
      "503530 h\n"
     ]
    }
   ],
   "source": [
    "for i, unique_term in enumerate(unique_terms):\n",
    "    if unique_term in sample_clinical_text:\n",
    "        print(i, unique_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e7027b-ed6a-477a-977d-8cc43e9c0d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c111aa0-b577-4f04-b212-3456b9ab8e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b626f31-ce49-4e03-8259-7d8224b78a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48ebd7-034d-452e-94e5-d4162658026c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6f6970-95b2-4401-8dd8-b73d6763d1dc",
   "metadata": {},
   "source": [
    "### Separate negated terms using NegEx\n",
    "\n",
    "TO DO: baca lagi code examplenya negex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e935615-c97e-4b62-a922-3c79be4e6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from ordered_set import OrderedSet #4.0.2\n",
    "\n",
    "from negex.python.negex import negTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edcfe06-1e6b-42ab-9753-3e05c445f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_negated_terms(sentence):\n",
    "    negated_term_count = sentence.count('[NEGATED]')//2\n",
    "    \n",
    "    negated_terms = OrderedSet()\n",
    "    if negated_term_count > 0:\n",
    "        unpack_negated_words = sentence.split('[NEGATED]')\n",
    "        for i in range(negated_term_count):\n",
    "            # store negated terms\n",
    "            negated_term = unpack_negated_words[2*(i+1)-1]\n",
    "            negated_terms.append(negated_term)\n",
    "\n",
    "    return negated_terms\n",
    "\n",
    "def get_patients_negated_terms(negex_triggers_text_filepath = './negex/python/negex_triggers.txt',\n",
    "                               patients_clinical_reports_text_filepath = './negex/python/Annotations-1-120.txt'):\n",
    "    \n",
    "    rfile = open(negex_triggers_text_filepath)\n",
    "    reports = csv.reader(open(patients_clinical_reports_text_filepath,'r'), delimiter = '\\t')\n",
    "    \n",
    "    irules = sortRules(rfile.readlines())\n",
    "\n",
    "    count = 0\n",
    "    tagged_sentences = []\n",
    "    for i, row in enumerate(reports):\n",
    "        #skip header\n",
    "        if count == 0:\n",
    "            count = count+1\n",
    "            continue\n",
    "        if count == 1:\n",
    "            tagger = negTagger(sentence = row[2], phrases = [row[1]], rules = irules, negP=False)\n",
    "            tagged_sentences.append(tagger.getNegTaggedSentence())\n",
    "\n",
    "    patients_negated_terms = []\n",
    "    for i, sentence in enumerate(tagged_sentences):\n",
    "        negated_terms = find_negated_terms(sentence)\n",
    "\n",
    "        # store the patient's negated terms\n",
    "        patients_negated_terms.append(negated_terms)\n",
    "        \n",
    "    rfile.close()\n",
    "        \n",
    "    return patients_negated_terms, tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68889ef-90ff-4dd9-afcc-0574610badd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "patients_negated_terms, tagged_sentences = get_patients_negated_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e44ff0-78a5-4101-b7ad-a4e90fd65181",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487e20b-4728-493a-ab31-c9285684ac97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6114f1e4-25d9-4cf7-b682-e2ae0d85d4b5",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Output the negated and non-negated terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c56b1-c22c-4fe8-988f-aa94ca0995c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a403a2b-471e-4610-ba70-9dd6100afb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf39ea0-de9b-4dee-a1af-8ef19b587cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3f12b-bab8-4661-a532-ca92400d683a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b340df-9594-4ee9-9cb6-4cc594cb8a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fce6b5-a1e7-4707-9cdf-8f252e9dbd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac89e21-65a2-4f90-987b-d2607b250a84",
   "metadata": {},
   "source": [
    "### Additional info\n",
    "\n",
    "Steps:\n",
    "1. Gather dataset\n",
    "2. Preprocess using Open Biomedical Annotator\n",
    "    - Normalize records:\n",
    "        - if data type = :\n",
    "            - __diagnoses, medications, procedures, lab tests__: count presence of each normalized code in patient EHRs<br>\n",
    "                → aiming to facilitate the modelling of related clinical events\n",
    "            - __free text clinical notes__: LePendu et al:\n",
    "                - Allowed identifying the negated tags and those related to family history\n",
    "                    - A tag that appeared as negated in the note was considered not relevant and discarded <br>\n",
    "                      → Negated tags were identified using NegEx:\n",
    "                              a regular expression algorithm that implements several phrases indicating negation:\n",
    "                              - filters out sentences containing phrases that falsely appear to be negation phrases,\n",
    "                              - and limits the scope of the negation phrases23\n",
    "                    - A tag that was related to family history was just flagged as such and differentiated from the directly patient-related tags.\n",
    "                    - We then analyzed similarities in the representation of temporally consecutive notes to remove duplicated information (e.g., notes recorded twice by mistake)\n",
    "                \n",
    "                - The parsed notes were further processed to reduce the sparseness of the representation (about 2 million normalized tags were extracted) and to obtain a semantic abstraction of the embedded clinical information. \n",
    "                    - To this aim we modeled the parsed notes using topic modeling <br>\n",
    "                        → an unsupervised inference process that captures patterns of word co-occurrences within documents to define topics and represent a document as a multinomial over these topics.<br>\n",
    "                             → Topic modeling has been applied to generalize clinical notes and improve automatic processing of patients data in several studies (e.g., see5,26–28). <br>\n",
    "                        → We used latent Dirichlet allocation as our implementation of topic modeling and we estimated the number of topics through perplexity analysis over one million random notes. <br>\n",
    "                        We found that 300 topics obtained the best mathematical generalization; therefore, each note was eventually summarized as a multinomial of 300 topic probabilities. <br>\n",
    "                        For each patient, we eventually retained one single topic-based representation averaged over all the notes available before the split-point.\n",
    "                        \n",
    "                        \n",
    "# HADCL Goals\n",
    "\n",
    "- Analyze the trade-off of applying traditional approach with recent sequence modeling approach for modeling EHR data\n",
    "- Benchmarking different pretrained language models for understanding EHR data\n",
    "- Exploring the use of EHR data allocation estimation in Hong Kong population\n",
    "    - Unplanned readmission\n",
    "    - Mortality risk\n",
    "    - Disease diagnosis\n",
    "    - Length of stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2730019-4d50-454b-b8c5-9e50d84dc312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock data\n",
    "\n",
    "mock_data = {}\n",
    "mock_data['age'] = [30,29,60]\n",
    "mock_data['gender'] = ['M', 'F', 'M']\n",
    "mock_data['race'] = ['race_a', 'race_b', 'race_a']\n",
    "mock_data['diagnoses'] = [['001', '139', '140', '239'],\n",
    "                          ['005', '199', '240', '533', '213', '343'],\n",
    "                          ['009', '239', '440', '335', '213']]\n",
    "mock_data['medications'] = [['A', 'B', 'C', 'D'],\n",
    "                            ['Z', 'A', 'D', 'W', 'A', 'B'],\n",
    "                            ['A', 'F', 'N', 'G', 'C']]\n",
    "mock_data['procedures'] = [['A', 'B', 'C', 'D'],\n",
    "                            ['Z', 'A', 'D', 'W', 'A', 'B'],\n",
    "                            ['A', 'F', 'N', 'G', 'C']]\n",
    "mock_data['lab_tests'] = [['A', 'B', 'C', 'D'],\n",
    "                            ['Z', 'A', 'D', 'W', 'A', 'B'],\n",
    "                            ['A', 'F', 'N', 'G', 'C']]\n",
    "mock_data['free_text_clinical_notes'] = [['ut aut reiciendis voluptatibu', 'erum hic tenetur a sapie', ' molestiae non recus', 'ur aut perferendi'],\n",
    "                            ['ctus, s maiores alias consequats dolorib', ' et molestiae non recusandae. Itaqu', ' rnte delectus, s maiores ali', 'onsequats doloribus asperiores repellat.', 'facere possimus, omnis voluptas ass', 'officiis debitis aut rerum necessi'],\n",
    "                            ['laceat, umenda est, omnis dolor rep', ' Temporibus autem quibusdam et aut ', 't, ut et voluptates repudiand', 'evenieae sinte earumas c', 'quod maxime pellendus.tatibus saepe ']]\n",
    "\n",
    "\n",
    "df_demog_clinidesc = pd.DataFrame(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e618c85-8cce-42bc-ad15-eb3037befd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openbiomedicalannotator(all_clinical_records=True):\n",
    "    if all_clinical_records:\n",
    "#         return harmonized_codes_for_procedures_and_lab_tests,\\\n",
    "#                 normalized_medications_based_on_brand_name_and_dosage,\\\n",
    "#                 extracted_clinical_concepts_from_free_text_notes\n",
    "        return pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a40c0c-7614-4e75-bc23-4218c921d6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab261c-fe62-4802-ae6e-c764fef0a31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab66554-ab0d-4962-95cd-c050f9596e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c6bd5-76a1-4f3b-b2f8-9909c77a504e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343846d-642d-4de5-82e4-36b44bf43fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8559a10-d843-4e5d-b5a2-b335717de26e",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053fa25-752c-4cc4-9f8b-6cd243dbe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "\n",
    "# icd9_cm_v32 = path + 'ICD-9-CM-v32-master-descriptions/' #\n",
    "# df_term = pd.read_excel(icd9_cm_v32 + 'CMS32_DESC_LONG_SHORT_SG.xlsx')\n",
    "# df_term.head()\n",
    "\n",
    "# sample_clinical_text = \"This is a 31 year old male s/p seizure on ladder with resulting fall 15-20 feet on [**09-17**] now presenting to the T/SICU post surgical repair of multiple facial fractures, right mandibular fracture, and left distal radius fracture. He needs to remain intubated for 48 hours post-op. His past medical history is significant only for seizure disorder, and his only medication is depakote. He has no known allergies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d9ba9-f2da-4804-848b-8dbbfd3ca34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "\n",
    "# ICD10       = PYM[\"ICD10\"]\n",
    "# SNOMEDCT_US = PYM[\"SNOMEDCT_US\"]\n",
    "# CUI         = PYM[\"CUI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9def2f-7a82-4237-95ee-9d4b8eb1cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "## for inspecting purposes\n",
    "\n",
    "# default_world.set_backend(filename = \"pym.sqlite3\")\n",
    "# include more from: https://www.nlm.nih.gov/research/umls/sourcereleasedocs/index.html\n",
    "# import_umls(\"umls-2021AB-full.zip\", terminologies = [\"ICD10\", \"SNOMEDCT_US\", \"CUI\"])\n",
    "# default_world.save()\n",
    "\n",
    "# %%time\n",
    "# count = 0\n",
    "# for i in range(len(PYM_classes_list)):\n",
    "#     str_class_selected = str(PYM_classes_list[i])\n",
    "#     if '_' in str_class_selected and 'SNOMEDCT_US' not in str_class_selected:\n",
    "#         count += 1\n",
    "#         print(i, str(PYM_classes_list[i]))\n",
    "#         if count == 1000:\n",
    "#             break\n",
    "\n",
    "# list(default_world.sparql(\"\"\"\n",
    "#            SELECT (COUNT(?x) AS ?nb)\n",
    "#            { ?x a owl:Class . }\n",
    "#     \"\"\"))\n",
    "\n",
    "# select_all_list = list(default_world.sparql(\"\"\"\n",
    "#                                select *\n",
    "#                                {?s a owl:Class.}\n",
    "#                         \"\"\"))\n",
    "\n",
    "# PYM.__dict__\n",
    "# type(PYM.get_children_of(ICD10[\"K44\"])[0])\n",
    "\n",
    "# a = PYM.get_children_of(ICD10[\"K44\"])[0]\n",
    "# a.mro()\n",
    "\n",
    "# PYM.get_children_of(ICD10[\"K44\"])[0].is_a\n",
    "\n",
    "# PYM.get_children_of(SNOMEDCT_US[\"346453007\"])\n",
    "\n",
    "# SNOMEDCT_US[186675001]\n",
    "\n",
    "# SNOMEDCT_US[186675001] >> ICD10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a2c7a-83dd-4f7b-bbe7-03b7949606c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "\n",
    "# onto_path.append('data_pool/Read_V22015.owl')\n",
    "# link = \"https://bioportal.bioontology.org/ontologies/CSO\"\n",
    "\n",
    "# link = \"https://data.bioontology.org/ontologies/CSO/submissions/1/download?apikey=6ff7e312-2d31-49ab-8163-5faa3568fa6f\"\n",
    "# onto = get_ontology(link)\n",
    "# onto.load()\n",
    "\n",
    "# onto = get_ontology(\"file:///home/bryan/hadcl/data_pool/Read_V22015.owl\").load()\n",
    "\n",
    "# len(list(onto.classes()))\n",
    "\n",
    "# for annot_prop in onto.metadata:\n",
    "#     print(annot_prop, \":\", annot_prop[onto.metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f3e0e-b3c7-4898-9f2b-d7d1227b8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated\n",
    "\n",
    "# list_count, tagged_sentences, negation_flags, scopes = [], [], [], []\n",
    "\n",
    "# count = 0\n",
    "# for i, row in enumerate(reports):\n",
    "#     if count == 0:\n",
    "#         count = count+1\n",
    "#         continue\n",
    "#     if count == 1:\n",
    "#         tagger = negTagger(sentence = row[2], phrases = [row[1]], rules = irules, negP=False)\n",
    "#         if len(tagger.getScopes()) > 0:\n",
    "#             if len(tagger.getScopes()[0])  >1:\n",
    "#                 print('tagger.getNegTaggedSentence()\\n', tagger.getNegTaggedSentence(), '\\n')\n",
    "#                 print('tagger.getNegationFlag()\\n', tagger.getNegationFlag(), '\\n')\n",
    "#                 print('tagger.getScopes()\\n', tagger.getScopes(), '\\n')\n",
    "#                 tagged_sentences.append(tagger.getNegTaggedSentence())\n",
    "#                 negation_flags.append(tagger.getNegationFlag())\n",
    "#                 scopes.append(tagger.getScopes())\n",
    "#                 list_count.append(i)\n",
    "#         if count > 3:\n",
    "#             break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
