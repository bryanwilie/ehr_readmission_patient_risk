{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d96543f-b935-4a42-9b63-d7e7f23dbc5a",
   "metadata": {},
   "source": [
    "## Reproducing LePendu et al\n",
    "\n",
    "Annotates clinical text from EHR systems -> __extract disease and drug mentions from the EHR.__<br>\n",
    "\n",
    "Re-read the paper again!\n",
    "\n",
    "### More to do\n",
    "- Obtaining ICD9 discharge codes<br>\n",
    "Patient visits include in some cases the discharge diagnosis in the form of an ICD9 code. <br>\n",
    "The ICD9 codes for rheumatoid arthritis begin with 714 and the ICD9 code for myocardial infarction begins with 410. <br>\n",
    "We __include these manually encoded terms as part of the analysis__ as a __comparison against what we can find in the text itself__.\n",
    "- We are also extending the system to discern additional contextual cues such as family history versus recent diagnosis.\n",
    "\n",
    "### More details\n",
    "- More terminologies [UMLS Metathesaurus Vocabulary Documentation](nlm.nih.gov/research/umls/sourcereleasedocs/index.html), [VSAC Downloadable Resources](https://vsac.nlm.nih.gov/download/ccda?rel=20210810), [CDE](https://cde.nlm.nih.gov/home)<br>\n",
    "- Some guide on querying: [How to extract/get all the terms(classes/properties) in an ontology](https://stackoverflow.com/questions/52655960/how-to-extract-get-all-the-termsclasses-properties-in-an-ontology), [querying the owl ontology](https://stackoverflow.com/questions/22542348/querying-the-owl-ontology), [SPARQL query](https://owlready2.readthedocs.io/en/v0.35/sparql.html)\n",
    "\n",
    "### HADCL Goals\n",
    "\n",
    "- Analyze the trade-off of applying traditional approach with recent sequence modeling approach for modeling EHR data\n",
    "- Benchmarking different pretrained language models for understanding EHR data\n",
    "- Exploring the use of EHR data allocation estimation in Hong Kong population\n",
    "    - Unplanned readmission\n",
    "    - Mortality risk\n",
    "    - Disease diagnosis\n",
    "    - Length of stay\n",
    "\n",
    "## 1. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86901e4d-a098-4a73-954b-629f4787f4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100) \n",
    "\n",
    "from terminology import obtain_terminologies\n",
    "from annotate import get_patients_annotated_terms\n",
    "from helper import temporally_ordered_list_join\n",
    "\n",
    "path = 'data_pool/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7797336f-3244-4e83-bdb3-0b2fd654c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_clinical_text = \"This is a 31 year old male s/p seizure on ladder with resulting fall 15-20 feet on [**09-17**] now presenting to the T/SICU post surgical repair of multiple facial fractures, open reduction of mandibular fracture, right mandibular fracture, and left distal radius fracture. He needs to remain intubated for 48 hours post-op. His past medical history is significant only for seizure disorder, and his only medication is depakote. He has no known allergies.\"\n",
    "                        # (the \"Open reduction of mandibular fracture\" is fabricated)\n",
    "\n",
    "# mimic_iii_demo = path + 'mimic-iii-clinical-database-demo-1.4/'\n",
    "# df = pd.read_csv(mimic_iii_demo + 'D_ICD_DIAGNOSES.csv')\n",
    "# print('df.iloc[0][\\'long_title\\']', df.iloc[0]['long_title'])\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5adf1d-2817-4f08-bcfc-26a16b2089f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report No.</th>\n",
       "      <th>Concept</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>shortness of breath</td>\n",
       "      <td>S_O_H  Counters Report Type Record Type Subgroup Classifier  1,01TdvtyYejbW DS DS 1504  E_O_H  [...</td>\n",
       "      <td>Affirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>staph   bacteremia</td>\n",
       "      <td>S_O_H  Counters Report Type Record Type Subgroup Classifier  1,01TdvtyYejbW DS DS 1504  E_O_H  [...</td>\n",
       "      <td>Affirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>infection</td>\n",
       "      <td>The patient was transferred to **INSTITUTION for   explantation of a pacemaker system that was f...</td>\n",
       "      <td>Affirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>infection</td>\n",
       "      <td>The patient was sent back to **INSTITUTION the   following day for further evaluation and manage...</td>\n",
       "      <td>Affirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>infection</td>\n",
       "      <td>It was   planned to follow up in the **INSTITUTION for reimplantation of the   pacemaker once th...</td>\n",
       "      <td>Affirmed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Report No.              Concept  \\\n",
       "0           1  shortness of breath   \n",
       "1           1   staph   bacteremia   \n",
       "2           1            infection   \n",
       "3           1            infection   \n",
       "4           1            infection   \n",
       "\n",
       "                                                                                              Sentence  \\\n",
       "0  S_O_H  Counters Report Type Record Type Subgroup Classifier  1,01TdvtyYejbW DS DS 1504  E_O_H  [...   \n",
       "1  S_O_H  Counters Report Type Record Type Subgroup Classifier  1,01TdvtyYejbW DS DS 1504  E_O_H  [...   \n",
       "2  The patient was transferred to **INSTITUTION for   explantation of a pacemaker system that was f...   \n",
       "3  The patient was sent back to **INSTITUTION the   following day for further evaluation and manage...   \n",
       "4  It was   planned to follow up in the **INSTITUTION for reimplantation of the   pacemaker once th...   \n",
       "\n",
       "   Negation  \n",
       "0  Affirmed  \n",
       "1  Affirmed  \n",
       "2  Affirmed  \n",
       "3  Affirmed  \n",
       "4  Affirmed  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./negex/python/Annotations-1-120.txt', delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80275247-8148-4703-899a-b0212f36f74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2376, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea0d94d-53ab-4f1d-ad21-2656d2c29880",
   "metadata": {},
   "source": [
    "## 2. Obtaining terminologies\n",
    "\n",
    "Obtained are UMLS terminologies: SNOMEDCT_US; RXNORM; NDFRT, and Human Disease Ontology<br>\n",
    "Ontologies are downloaded from [UMLS](https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html) and [OLS Ontology Search](https://www.ebi.ac.uk/ols/ontologies/doid) (umls-2021AB-full.zip), using ([Owlready2](https://pypi.org/project/Owlready2/) | [Source](https://bitbucket.org/jibalamy/owlready2/src/master/doc/))<br>\n",
    "\n",
    "__TODO__:\n",
    "1. Need to also include __manually encoded ICD9 terms__ for each patient encounter as additional terms\n",
    "2. Combine with coded and structured data when possible\n",
    "3. The resulting lexicon contains __2.8 million unique terms.__, gathered are only 550k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a76d39dd-786a-4918-8c79-63397bb6201a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing UMLS from umls-2021AB-full.zip with Python version 3.8.8 and Owlready version 2-0.35...\n",
      "Full UMLS release - importing UMLS from inner Zip file 2021AB-full/2021ab-1-meta.nlm...\n",
      "  Parsing 2021AB/META/MRRANK.RRF.gz as MRRANK with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRCONSO.RRF.aa.gz as MRCONSO with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRCONSO.RRF.ab.gz as MRCONSO with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRDEF.RRF.gz as MRDEF with encoding UTF-8\n",
      "Full UMLS release - importing UMLS from inner Zip file 2021AB-full/2021ab-2-meta.nlm...\n",
      "  Parsing 2021AB/META/MRREL.RRF.aa.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRREL.RRF.ab.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRREL.RRF.ac.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRREL.RRF.ad.gz as MRREL with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.aa.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ab.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ac.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ad.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.ae.gz as MRSAT with encoding UTF-8\n",
      "  Parsing 2021AB/META/MRSAT.RRF.af.gz as MRSAT with encoding UTF-8\n",
      "Breaking ORIG cycles...\n",
      "    RXNORM : 0 cycles found: \n",
      "    SNOMEDCT_US : 0 cycles found: \n",
      "    SRC : 0 cycles found: \n",
      "Finalizing only properties and restrictions...\n",
      "Finalizing CUI - ORIG mapping...\n",
      "FTS Indexing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: DtypeWarning: Columns (8,52,66,72,79) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'choose_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/ehr_readmission_patient_risk/terminology.py\u001b[0m in \u001b[0;36mobtain_terminologies\u001b[0;34m(terminologies, hdo, additional_from_negex)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdf_hdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Human Disease Ontology/DOID.csv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdf_hdo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_hdo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchoose_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mdf_hdo_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_hdo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_hdo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Obsolete'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'definition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Synonyms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_indonlg/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8734\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8735\u001b[0m         )\n\u001b[0;32m-> 8736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8738\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/anaconda3/envs/env_indonlg/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_indonlg/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_indonlg/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ehr_readmission_patient_risk/terminology.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdf_hdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Human Disease Ontology/DOID.csv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdf_hdo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_hdo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchoose_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mdf_hdo_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_hdo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_hdo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Obsolete'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'definition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Synonyms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'choose_label' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unique_terms = obtain_terminologies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57336eb-3061-40fb-92f4-8115659d4003",
   "metadata": {},
   "source": [
    "# 3. Annotate the recognized and negated terms\n",
    "\n",
    "Annotate by string matching the text to the lexicon downloaded, and apply negex trigger rules to separate negated terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68889ef-90ff-4dd9-afcc-0574610badd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_terms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_terms' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_result = get_patients_annotated_terms(unique_terms[:10], df)\n",
    "df_result.to_csv('result.csv', index=False)\n",
    "df_result = pd.read_csv('result.csv')\n",
    "df_result.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da452438-d27b-41bd-80ba-e22ae68db7fc",
   "metadata": {},
   "source": [
    "## 4. Compile terms for timeline view of the patient's record\n",
    "\n",
    "We compile terms (From each note, output:set of negated terms, set of non-negated terms) into a temporally ordered series of sets for each patient to create a timeline view of the patient’s record.\n",
    "\n",
    "The patient id and admission date are now __mocked__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d74cd7-b2c2-454f-a63d-d5cc0b64fcf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49366/824766448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrandom_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmonth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_result' is not defined"
     ]
    }
   ],
   "source": [
    "# mock id and admission date\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "random_id, random_date = [], []\n",
    "for i in range(df_result.shape[0]):\n",
    "    n = random.randint(1,30)\n",
    "    month = random.randint(1,12)\n",
    "    day = random.randint(1,28)\n",
    "    random_date.append(datetime.date(2020, month, day))\n",
    "    random_id.append(n)\n",
    "    \n",
    "df_result['patient_id'] = random_id\n",
    "df_result['admission_date'] = random_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb358cc-05b0-4ecd-b810-1dfa95f2003c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_grouped_pos = df_result.sort_values(['patient_id', 'admission_date']).groupby(['patient_id'])['recognized_terms'].apply(temporally_ordered_list_join).reset_index()\n",
    "df_result_grouped_neg = df_result.sort_values(['patient_id', 'admission_date']).groupby(['patient_id'])['negated_terms'].apply(temporally_ordered_list_join).reset_index()\n",
    "df_result_grouped = df_result_grouped_pos.merge(df_result_grouped_neg, on='patient_id', how='left')\n",
    "df_result_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a355c-271c-4280-a211-bc4cad748f00",
   "metadata": {},
   "source": [
    "## 5. Normalize and aggregate terms\n",
    "\n",
    "Use the __RxNORM terminology__ to normalize the drug having the trade name Vioxx into its primary active ingredient,\n",
    "\n",
    "We reason over the structure of the ontologies to normalize and to aggregate terms for further analysis<br>\n",
    "From the set of ontologies we use, the Annotator identifies all notes containing any string denoting this term as either its primary label or synonym.<br>\n",
    "We use __all other ontologies to normalize strings denoting rheumatoid arthritis or myocardial infarction__ and the Annotator identifies all notes containing them.<br>\n",
    "As an option, we can also enable reasoning to infer all subsumed terms, which increases the number of notes that we can identify beyond pure string matches.<br>\n",
    "For example, patients with Caplan’s or Felty’s syndrome may also fit the cohort of patients with rheumatoid arthritis.<br>\n",
    "Therefore, notes that mention these diseases can automatically be included as well even though their associated strings look nothing alike.<br>\n",
    "We did not use such reasoning for results reported in this specific study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24b1f5-4f5c-4c94-8bc7-c528fb9e8f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ad262-e270-4b99-a120-55d59d553fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb18bc-671e-4f04-9997-a451fdf83c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62782e82-0af6-46fc-8a40-b8ec6f5411ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8559a10-d843-4e5d-b5a2-b335717de26e",
   "metadata": {},
   "source": [
    "6. Finishing Touches\n",
    "\n",
    "__TO DO__:\n",
    "- Using the terms as features, we can define patterns of interest (such as patients with rheumatoid arthritis, who take rofecoxib, and then get myocardial infarctio), which we can use in data mining applications.# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a1873-670a-466c-82de-25525ebecb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac89e21-65a2-4f90-987b-d2607b250a84",
   "metadata": {},
   "source": [
    "### Additional info\n",
    "\n",
    "Steps:\n",
    "1. Gather dataset\n",
    "2. Preprocess using Open Biomedical Annotator\n",
    "    - Normalize records:\n",
    "        - if data type = :\n",
    "            - __diagnoses, medications, procedures, lab tests__: count presence of each normalized code in patient EHRs<br>\n",
    "                → aiming to facilitate the modelling of related clinical events\n",
    "            - __free text clinical notes__: LePendu et al:\n",
    "                - Allowed identifying the negated tags and those related to family history\n",
    "                    - A tag that appeared as negated in the note was considered not relevant and discarded <br>\n",
    "                      → Negated tags were identified using NegEx:\n",
    "                              a regular expression algorithm that implements several phrases indicating negation:\n",
    "                              - filters out sentences containing phrases that falsely appear to be negation phrases,\n",
    "                              - and limits the scope of the negation phrases\n",
    "                    - A tag that was related to family history was just flagged as such and differentiated from the directly patient-related tags.\n",
    "                    - We then analyzed similarities in the representation of temporally consecutive notes to remove duplicated information (e.g., notes recorded twice by mistake)\n",
    "                \n",
    "                - The parsed notes were further processed to reduce the sparseness of the representation (about 2 million normalized tags were extracted) and to obtain a semantic abstraction of the embedded clinical information. \n",
    "                    - To this aim we modeled the parsed notes using topic modeling <br>\n",
    "                        → an unsupervised inference process that captures patterns of word co-occurrences within documents to define topics and represent a document as a multinomial over these topics.<br>\n",
    "                             → Topic modeling has been applied to generalize clinical notes and improve automatic processing of patients data in several studies (e.g., see5,26–28). <br>\n",
    "                        → We used latent Dirichlet allocation as our implementation of topic modeling and we estimated the number of topics through perplexity analysis over one million random notes. <br>\n",
    "                        We found that 300 topics obtained the best mathematical generalization; therefore, each note was eventually summarized as a multinomial of 300 topic probabilities. <br>\n",
    "                        For each patient, we eventually retained one single topic-based representation averaged over all the notes available before the split-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc08b5-c729-49ee-8226-34614573ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "\n",
    "# for i, term in enumerate(split_semicolons_term):\n",
    "#     if 'mandibular fracture' in term:\n",
    "#         print(i, term)\n",
    "\n",
    "# for term in split_semicolons_term:\n",
    "#     if len(term) <3:\n",
    "#         print(term)\n",
    "\n",
    "# terms = []\n",
    "# for i in range(len(PYM_classes_list)):\n",
    "#     str_class_selected = str(PYM_classes_list[i])\n",
    "#     if '#' in str_class_selected:\n",
    "#         strings_selected = str_class_selected[str_class_selected.index('#')+2:-1].replace(' ; ',';').split('; ')\n",
    "#         if 'H' in strings_selected:\n",
    "#             print(str_class_selected, strings_selected)\n",
    "#         terms.extend(strings_selected)\n",
    "\n",
    "# recognized_terms = []\n",
    "# for term in split_semicolons_term:\n",
    "#     if ' ' + term.lower() + ' ' in sample_clinical_text:\n",
    "#         recognized_terms.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053fa25-752c-4cc4-9f8b-6cd243dbe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "\n",
    "# icd9_cm_v32 = path + 'ICD-9-CM-v32-master-descriptions/' #\n",
    "# df_term = pd.read_excel(icd9_cm_v32 + 'CMS32_DESC_LONG_SHORT_SG.xlsx')\n",
    "# df_term.head()\n",
    "\n",
    "# sample_clinical_text = \"This is a 31 year old male s/p seizure on ladder with resulting fall 15-20 feet on [**09-17**] now presenting to the T/SICU post surgical repair of multiple facial fractures, right mandibular fracture, and left distal radius fracture. He needs to remain intubated for 48 hours post-op. His past medical history is significant only for seizure disorder, and his only medication is depakote. He has no known allergies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d9ba9-f2da-4804-848b-8dbbfd3ca34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "\n",
    "# ICD10       = PYM[\"ICD10\"]\n",
    "# SNOMEDCT_US = PYM[\"SNOMEDCT_US\"]\n",
    "# CUI         = PYM[\"CUI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9def2f-7a82-4237-95ee-9d4b8eb1cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "## for inspecting purposes\n",
    "\n",
    "# default_world.set_backend(filename = \"pym.sqlite3\")\n",
    "# include more from: https://www.nlm.nih.gov/research/umls/sourcereleasedocs/index.html\n",
    "# import_umls(\"umls-2021AB-full.zip\", terminologies = [\"ICD10\", \"SNOMEDCT_US\", \"CUI\"])\n",
    "# default_world.save()\n",
    "\n",
    "# %%time\n",
    "# count = 0\n",
    "# for i in range(len(PYM_classes_list)):\n",
    "#     str_class_selected = str(PYM_classes_list[i])\n",
    "#     if '_' in str_class_selected and 'SNOMEDCT_US' not in str_class_selected:\n",
    "#         count += 1\n",
    "#         print(i, str(PYM_classes_list[i]))\n",
    "#         if count == 1000:\n",
    "#             break\n",
    "\n",
    "# list(default_world.sparql(\"\"\"\n",
    "#            SELECT (COUNT(?x) AS ?nb)\n",
    "#            { ?x a owl:Class . }\n",
    "#     \"\"\"))\n",
    "\n",
    "# select_all_list = list(default_world.sparql(\"\"\"\n",
    "#                                select *\n",
    "#                                {?s a owl:Class.}\n",
    "#                         \"\"\"))\n",
    "\n",
    "# PYM.__dict__\n",
    "# type(PYM.get_children_of(ICD10[\"K44\"])[0])\n",
    "\n",
    "# a = PYM.get_children_of(ICD10[\"K44\"])[0]\n",
    "# a.mro()\n",
    "\n",
    "# PYM.get_children_of(ICD10[\"K44\"])[0].is_a\n",
    "\n",
    "# PYM.get_children_of(SNOMEDCT_US[\"346453007\"])\n",
    "\n",
    "# SNOMEDCT_US[186675001]\n",
    "\n",
    "# SNOMEDCT_US[186675001] >> ICD10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a2c7a-83dd-4f7b-bbe7-03b7949606c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "\n",
    "# onto_path.append('data_pool/Read_V22015.owl')\n",
    "# link = \"https://bioportal.bioontology.org/ontologies/CSO\"\n",
    "\n",
    "# link = \"https://data.bioontology.org/ontologies/CSO/submissions/1/download?apikey=6ff7e312-2d31-49ab-8163-5faa3568fa6f\"\n",
    "# onto = get_ontology(link)\n",
    "# onto.load()\n",
    "\n",
    "# onto = get_ontology(\"file:///home/bryan/hadcl/data_pool/Read_V22015.owl\").load()\n",
    "\n",
    "# len(list(onto.classes()))\n",
    "\n",
    "# for annot_prop in onto.metadata:\n",
    "#     print(annot_prop, \":\", annot_prop[onto.metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f3e0e-b3c7-4898-9f2b-d7d1227b8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated\n",
    "\n",
    "# list_count, tagged_sentences, negation_flags, scopes = [], [], [], []\n",
    "\n",
    "# count = 0\n",
    "# for i, row in enumerate(reports):\n",
    "#     if count == 0:\n",
    "#         count = count+1\n",
    "#         continue\n",
    "#     if count == 1:\n",
    "#         tagger = negTagger(sentence = row[2], phrases = [row[1]], rules = irules, negP=False)\n",
    "#         if len(tagger.getScopes()) > 0:\n",
    "#             if len(tagger.getScopes()[0])  >1:\n",
    "#                 print('tagger.getNegTaggedSentence()\\n', tagger.getNegTaggedSentence(), '\\n')\n",
    "#                 print('tagger.getNegationFlag()\\n', tagger.getNegationFlag(), '\\n')\n",
    "#                 print('tagger.getScopes()\\n', tagger.getScopes(), '\\n')\n",
    "#                 tagged_sentences.append(tagger.getNegTaggedSentence())\n",
    "#                 negation_flags.append(tagger.getNegationFlag())\n",
    "#                 scopes.append(tagger.getScopes())\n",
    "#                 list_count.append(i)\n",
    "#         if count > 3:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf5249-b471-4960-946a-4a43673cdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mock data\n",
    "\n",
    "# mock_data = {}\n",
    "# mock_data['age'] = [30,29,60]\n",
    "# mock_data['gender'] = ['M', 'F', 'M']\n",
    "# mock_data['race'] = ['race_a', 'race_b', 'race_a']\n",
    "# mock_data['diagnoses'] = [['001', '139', '140', '239'],\n",
    "#                           ['005', '199', '240', '533', '213', '343'],\n",
    "#                           ['009', '239', '440', '335', '213']]\n",
    "# mock_data['medications'] = [['A', 'B', 'C', 'D'],\n",
    "#                             ['Z', 'A', 'D', 'W', 'A', 'B'],\n",
    "#                             ['A', 'F', 'N', 'G', 'C']]\n",
    "# mock_data['procedures'] = [['A', 'B', 'C', 'D'],\n",
    "#                             ['Z', 'A', 'D', 'W', 'A', 'B'],\n",
    "#                             ['A', 'F', 'N', 'G', 'C']]\n",
    "# mock_data['lab_tests'] = [['A', 'B', 'C', 'D'],\n",
    "#                             ['Z', 'A', 'D', 'W', 'A', 'B'],\n",
    "#                             ['A', 'F', 'N', 'G', 'C']]\n",
    "# mock_data['free_text_clinical_notes'] = [['ut aut reiciendis voluptatibu', 'erum hic tenetur a sapie', ' molestiae non recus', 'ur aut perferendi'],\n",
    "#                             ['ctus, s maiores alias consequats dolorib', ' et molestiae non recusandae. Itaqu', ' rnte delectus, s maiores ali', 'onsequats doloribus asperiores repellat.', 'facere possimus, omnis voluptas ass', 'officiis debitis aut rerum necessi'],\n",
    "#                             ['laceat, umenda est, omnis dolor rep', ' Temporibus autem quibusdam et aut ', 't, ut et voluptates repudiand', 'evenieae sinte earumas c', 'quod maxime pellendus.tatibus saepe ']]\n",
    "\n",
    "\n",
    "# df_demog_clinidesc = pd.DataFrame(mock_data)\n",
    "\n",
    "# def openbiomedicalannotator(all_clinical_records=True):\n",
    "#     if all_clinical_records:\n",
    "# #         return harmonized_codes_for_procedures_and_lab_tests,\\\n",
    "# #                 normalized_medications_based_on_brand_name_and_dosage,\\\n",
    "# #                 extracted_clinical_concepts_from_free_text_notes\n",
    "#         return pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
